Usarei isto para salvar o código, portanto ignorem o código, mas gostaria de ajuda para resolver o error 'oplexicon_v2.1' not found dessa extração:
devtools::install_github("sillasgonzaga/lexiconPT")
lexiconPT::get_word_sentiment('teste')






pacman::p_load(devtools, rtweet, tm, RColorBrewer, cluster, fpc, httpuv, SnowballC,
               ggplot2, wordcloud, wordcloud2, tidytext,
               stringr, tidyverse, knitr, png, webshot, htmlwidgets)
#Selecionando as base de dados do ifood e UberEats.
ifood = search_tweets("ifood", n = 8000, include_rts = FALSE,lang = "pt")
ifood = ifood[,c('text')]
UberE = search_tweets("uber_eats", n = 8000, include_rts = FALSE,lang = "pt")
UberE = UberE[,c('text')]
# Separar cada string em um conjunto de caractéres ser possivel detectar tweets maliciosos para a pesquisa e então removelos.
# Retirando o spam de Cupons(observei apenas esses 2 padrões).
length(ifood$text)
for(i in 1:(length(ifood$text))){
  if(stringr::str_sub(ifood$text[i],start = 0,end = 6) == 'CUPONS'){
    ifood$text[i] = '<>'
  }
  if(stringr::str_sub(ifood$text[i],start = 0,end = 6) == 'Quer c'){
    ifood$text[i] = '<>'
  }
  if(ifood$text[i] == '<>'){
    ifood$text[i] = NA        
  }
}
#mesmo processo para 'Ubereats'.
#Ánalise de sentimentos usando lexiconPT.
devtools::install_github("sillasgonzaga/lexiconPT")
lexiconPT::get_word_sentiment('teste')
#Efetuar o inner.join com a base dados para gerar o sentimento da mesma. 

## Sobre Clusters:
Eu peguei esses códigos desse site https://www.tidytextmining.com/sentiment.html no tópico 2.1
install.packages("tidytext")
library(tidytext)
library(janeaustenr)
library(dplyr)
library(stringr)

# Pegando os livros para análises
palavras_sentimentos <- austen_books() %>%
  group_by(book) %>%
  mutate(NumLinha = row_number(),
         capitulo = cumsum(str_detect(text, regex("^chapter [\\divxlc]", 
                                                 ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
  get_sentiments("nrc")

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

palavras_sentimentos %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

