require(devtools)
install_github("lchiffon/wordcloud2")

install.packages("pacman")
library(pacman)
pacman::p_load(rtweet, tm, RColorBrewer, cluster, fpc, httpuv, SnowballC, wordcloud, wordcloud2, tidytext, dplyr, stringr, rtweet, ggplot2)

#####
#Carregando os Tweets
#Voce precisar ter uma conta no Twitter e autorizar
#Limite de 18.000 tweets a cada 15 minutos
twitterUnB <- search_tweets("unb", n = 18000, include_rts = FALSE,lang = "pt")

#####
#Criando e limpando o corpus
corpusUnB <- VCorpus(VectorSource(as.character(as.matrix(twitterUnB$text))))
corpusUnB <- tm_map(corpusUnB, removePunctuation)
corpusUnB <- tm_map(corpusUnB, removeWords, stopwords("pt"))
corpusUnB <- tm_map(corpusUnB, removeWords, c("nao", "porque", 
                                              "entao", "tá", "tô", "pra", "pro", "cê",
                                              "quer", "que", "aqui", "como", "meu",
                                              "ela", "era", "com", "seu", "sou",
                                              "por", "foi", "vou", "sim", "fica", "ter", "ele",
                                              "eu", "voce", "nos", "eles", "elas", "sao", "sou",
                                              "e", "quero", "quis", "minha", "tenho", "estou", "isso",
                                              "essa", "ser", "tem", "seus", "sem", "pelo", "uma", "quem",
                                              "isso", "para", "mas", "vai", "pois", "ver", "vcs", "fazer",
                                              "mais", "tudo", "entrar", "indo", "vem", "das",
                                              "muit0", "meus", "acho", "muito", "ficar", "nada",
                                              "tava", "tinha", "mesmo", "queria", "toda", "fui", 
                                              "nessa", "mim", "esse", "sei", "sair", "pela", "dia", "faz",
                                              "dar", "unb"))

#Mas ainda aparece muito lixo
#####
#Convertendo a matriz de frequencia em dataframe para o plot
unb_frequencia <- sort(colSums(as.matrix(removeSparseTerms(DocumentTermMatrix(corpusUnB), 0.995))), decreasing=TRUE)
length(unb_frequencia) 
tail(unb_frequencia,10)
unb_frequencia

#Convertendo a matriz de frequencia em dataframe para o plot
unb_plot <- data.frame(word=names(unb_frequencia), freq=unb_frequencia)
unb_plot <- unb_plot[-c(1),]

#Fazendo a nuvem de palavras
wordcloud2(unb_plot) 
